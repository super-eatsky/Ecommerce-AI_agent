# ğŸ›’ E-commerce AI Agent with Local LLM (LLaMA 3)

This project is an intelligent AI agent that understands natural language questions related to e-commerce metrics and returns accurate answers by generating and executing SQL queries on a local database. It uses a locally hosted LLaMA 3 model via Ollama, integrates with FastAPI, and supports streamed responses for a live typing effect.

---

## ğŸš€ Features

- ğŸ”— Natural language to SQL query conversion using LLaMA 3
- ğŸ§  Local LLM hosting via [Ollama](https://ollama.com)
- ğŸ“Š Executes SQL on structured SQLite e-commerce datasets
- ğŸ’¬ FastAPI backend with RESTful endpoints
- ğŸ“¥ `POST /ask` for direct Q&A
- âœ¨ `POST /stream` for real-time typing effect
- ğŸ“ Modular codebase: easy to understand and extend
- ğŸ¯ Tested on real-world marketing and product datasets

---

## ğŸ“‚ Project Structure

E-commerce_ai_agent/
â”‚
â”œâ”€â”€ api_server.py               # FastAPI endpoints (/ask and /stream)
â”œâ”€â”€ llama_sql_generator.py      # LLM prompt + SQL generation logic
â”œâ”€â”€ llama_sql_executor.py       # SQL execution & safety check logic
â”œâ”€â”€ load_data_to_db.py          # Loads Excel files into SQLite DB
â”œâ”€â”€ test_database_queries.py    # Simple test queries
â”œâ”€â”€ *.xlsx                      # Raw datasets (mapped to SQL tables)
â”œâ”€â”€ ecommerce.db                # SQLite database (auto-created)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # Project documentation

---

## ğŸ“¦ Dependencies

Install the following before running the app:

```bash
pip install -r requirements.txt

Make sure you have Ollama installed and running with:

ollama run llama3


â¸»

â–¶ï¸ How to Run
	1.	Activate virtual environment (if not already):

source .venv/bin/activate

	2.	Start the FastAPI server:

uvicorn api_server:app --reload

	3.	Test queries using cURL:

curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is my total sales?"}' | jq

	4.	Try streaming (typing effect):

curl -N -X POST http://localhost:8000/stream \
  -H "accept: text/plain" \
  -H "Content-Type: application/json" \
  -d '{"question": "How do you calculate ROAS?"}'


â¸»

ğŸ§  Example Questions
	â€¢	What is my total sales?
	â€¢	Calculate the RoAS (Return on Ad Spend).
	â€¢	Which product had the highest CPC?
	â€¢	Show total ad spend per month.
	â€¢	What is the average CTR by month?
	â€¢	List top 5 products by ad sales.
	â€¢	How many clicks did each product receive?
	â€¢	Which product had the lowest RoAS?
	â€¢	What is the total number of impressions?

â¸»

ğŸ›  Tech Stack

Component	Tech Used
LLM	LLaMA 3 via Ollama
Backend	FastAPI
Database	SQLite3
API Testing	cURL, Swagger
JSON Handling	jq (for formatted terminal output)
Dataset Format	Excel (XLSX â†’ SQLite)

â¸»

ğŸ“Œ Notes
	â€¢	All SQL queries are auto-validated to prevent unsafe operations.
	â€¢	All data is processed locally; no external LLM APIs are used.
	â€¢	For visualization support, Matplotlib can be optionally added (not enabled in current build).

â¸»

ğŸ“š Credits
	â€¢	LLaMA 3 hosted via Ollama
	â€¢	FastAPI team for clean REST API support
	â€¢	SQLite3 for a minimal yet powerful DB engine

â¸»

ğŸ§‘â€ğŸ’» Author

Gokularaman C
â¸»